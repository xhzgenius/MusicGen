{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\NLP2\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoProcessor, MusicgenForConditionalGeneration\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"device:\", device)\n",
    "\n",
    "model_name = \"facebook/musicgen-medium\"  # 可选：small, medium, large\n",
    "# 初次使用记得去掉local_files_only=True\n",
    "processor = AutoProcessor.from_pretrained(model_name, local_files_only=True)\n",
    "model = MusicgenForConditionalGeneration.from_pretrained(model_name, local_files_only=True).half().to(device)\n",
    "# model.half()解决精度问题报错"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since amaai-lab/MusicBench couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'default' at C:\\Users\\XHZGenius\\.cache\\huggingface\\datasets\\amaai-lab___music_bench\\default\\0.0.0\\b141e962aacc19ffd51c15732738040377989203 (last modified on Thu May 22 18:25:15 2025).\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "from datasets import Dataset\n",
    "import os\n",
    "\n",
    "def process_data(batch):\n",
    "    # 加载音频并标准化\n",
    "    audio, sr = librosa.load(os.path.join(\"./data/datashare/\", batch[\"location\"]), sr=32000)\n",
    "    \n",
    "    # 使用 processor 处理文本和音频\n",
    "    inputs = processor(\n",
    "        text=[batch[\"main_caption\"]],\n",
    "        audio=[audio],\n",
    "        sampling_rate=32000,\n",
    "        padding=True,\n",
    "        return_tensors=\"pt\",\n",
    "    ).to(device)\n",
    "    \n",
    "    return inputs\n",
    "\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"amaai-lab/MusicBench\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 52768/52768 [15:43<00:00, 55.94 examples/s]  \n",
      "Map: 100%|██████████| 800/800 [00:13<00:00, 60.94 examples/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['dataset', 'location', 'main_caption', 'alt_caption', 'prompt_aug', 'prompt_ch', 'prompt_bt', 'prompt_bpm', 'prompt_key', 'beats', 'bpm', 'chords', 'chords_time', 'key', 'keyprob', 'is_audioset_eval_mcaps', 'input_ids', 'attention_mask', 'input_values', 'padding_mask'],\n",
       "        num_rows: 52768\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['dataset', 'location', 'main_caption', 'alt_caption', 'prompt_aug', 'prompt_ch', 'prompt_bt', 'prompt_bpm', 'prompt_key', 'beats', 'bpm', 'chords', 'chords_time', 'key', 'keyprob', 'is_audioset_eval_mcaps', 'input_ids', 'attention_mask', 'input_values', 'padding_mask'],\n",
       "        num_rows: 800\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.map(process_data, batched=False)\n",
    "# dataset = dataset[\"train\"].train_test_split(test_size=0.2)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 设置训练参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 4,718,592 || all params: 2,009,969,730 || trainable%: 0.2348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "# 定义 LoRA 配置\n",
    "lora_config = LoraConfig(\n",
    "    r=8,                  # LoRA 的秩（Rank）\n",
    "    lora_alpha=32,        # 缩放因子\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],  # 目标模块（MusicGen 的注意力层）\n",
    "    lora_dropout=0.05,    # Dropout 率\n",
    "    bias=\"none\",          # 不调整偏置\n",
    "    task_type=\"CAUSAL_LM\", # 因果语言模型任务\n",
    ")\n",
    "\n",
    "# 应用 LoRA\n",
    "lora_model = get_peft_model(model, lora_config)\n",
    "lora_model.print_trainable_parameters()  # 查看可训练参数（应远小于原始模型）\n",
    "lora_model.save_pretrained(\"./outputs/musicgen-lora/initial_lora\")\n",
    "\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./outputs/musicgen-lora\",\n",
    "    per_device_train_batch_size=2,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=1e-4,  # LoRA 需要更高的学习率\n",
    "    fp16=True,           # 混合精度训练\n",
    "    logging_steps=100,\n",
    "    save_steps=500,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=lora_model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"test\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset': 'MusicBench',\n",
       " 'location': 'data_aug2/-0SdAVK79lg_1.wav',\n",
       " 'main_caption': 'This mellow instrumental track showcases a dominant electric guitar that opens with a descending riff, followed by arpeggiated chords, hammer-ons, and a slide. The percussion section keeps it simple with rim shots and a common time count, while the bass adds a single note on the first beat of every bar. Minimalist piano chords round out the song while leaving space for the guitar to shine. There are no vocals, making it perfect for a coffee shop or some chill background music. The key is in E major, with a chord progression that centers around that key and a straightforward 4/4 time signature.',\n",
       " 'alt_caption': 'This song features an electric guitar as the main instrument. The guitar plays a descending run in the beginning then plays an arpeggiated chord followed by a double stop hammer on to a higher note and a descending slide followed by a descending chord run. The percussion plays a simple beat using rim shots. The percussion plays in common time. The bass plays only one note on the first count of each bar. The piano plays backing chords. There are no voices in this song. The mood of this song is relaxing. This song can be played in a coffee shop. The key of this song is E major. The chord progression in this song is E. The beat counts to 4. ',\n",
       " 'prompt_aug': '',\n",
       " 'prompt_ch': 'The chord progression in this song is E.',\n",
       " 'prompt_bt': 'The beat counts to 4.',\n",
       " 'prompt_bpm': 'The bpm is 112.0.',\n",
       " 'prompt_key': 'The key of this song is E major.',\n",
       " 'beats': [[0.37212133669135816,\n",
       "   0.9070457581851855,\n",
       "   1.4652277632222228,\n",
       "   2.0234097682592598,\n",
       "   2.5583341897530874,\n",
       "   3.093258611246915,\n",
       "   3.628183032740742,\n",
       "   4.13984987069136,\n",
       "   4.6747742921851865,\n",
       "   5.232956297222224,\n",
       "   5.744623135172842,\n",
       "   6.326062723753089,\n",
       "   6.860987145246916,\n",
       "   7.372653983197533,\n",
       "   7.930835988234571,\n",
       "   8.442502826185187,\n",
       "   8.977427247679016,\n",
       "   9.535609252716052],\n",
       "  [4.0,\n",
       "   1.0,\n",
       "   2.0,\n",
       "   3.0,\n",
       "   4.0,\n",
       "   1.0,\n",
       "   2.0,\n",
       "   3.0,\n",
       "   4.0,\n",
       "   1.0,\n",
       "   2.0,\n",
       "   3.0,\n",
       "   4.0,\n",
       "   1.0,\n",
       "   2.0,\n",
       "   3.0,\n",
       "   4.0,\n",
       "   1.0]],\n",
       " 'bpm': 112.0,\n",
       " 'chords': ['E'],\n",
       " 'chords_time': [0.5400400339790407],\n",
       " 'key': ['E', 'major'],\n",
       " 'keyprob': [0.8934084177017212],\n",
       " 'is_audioset_eval_mcaps': False,\n",
       " 'input_ids': [[100,\n",
       "   3,\n",
       "   2341,\n",
       "   3216,\n",
       "   15205,\n",
       "   1463,\n",
       "   7193,\n",
       "   7,\n",
       "   3,\n",
       "   9,\n",
       "   12613,\n",
       "   2806,\n",
       "   5507,\n",
       "   24,\n",
       "   9540,\n",
       "   28,\n",
       "   3,\n",
       "   9,\n",
       "   3,\n",
       "   30960,\n",
       "   3,\n",
       "   17048,\n",
       "   6,\n",
       "   2348,\n",
       "   57,\n",
       "   1584,\n",
       "   855,\n",
       "   15406,\n",
       "   920,\n",
       "   20513,\n",
       "   7,\n",
       "   6,\n",
       "   3,\n",
       "   1483,\n",
       "   935,\n",
       "   18,\n",
       "   106,\n",
       "   7,\n",
       "   6,\n",
       "   11,\n",
       "   3,\n",
       "   9,\n",
       "   9116,\n",
       "   5,\n",
       "   37,\n",
       "   3,\n",
       "   19984,\n",
       "   1375,\n",
       "   5689,\n",
       "   34,\n",
       "   650,\n",
       "   28,\n",
       "   3,\n",
       "   5397,\n",
       "   6562,\n",
       "   11,\n",
       "   3,\n",
       "   9,\n",
       "   1017,\n",
       "   97,\n",
       "   3476,\n",
       "   6,\n",
       "   298,\n",
       "   8,\n",
       "   7981,\n",
       "   617,\n",
       "   7,\n",
       "   3,\n",
       "   9,\n",
       "   712,\n",
       "   2232,\n",
       "   30,\n",
       "   8,\n",
       "   166,\n",
       "   3853,\n",
       "   13,\n",
       "   334,\n",
       "   1207,\n",
       "   5,\n",
       "   4533,\n",
       "   1982,\n",
       "   343,\n",
       "   8355,\n",
       "   20513,\n",
       "   7,\n",
       "   1751,\n",
       "   91,\n",
       "   8,\n",
       "   2324,\n",
       "   298,\n",
       "   3140,\n",
       "   628,\n",
       "   21,\n",
       "   8,\n",
       "   5507,\n",
       "   12,\n",
       "   9567,\n",
       "   5,\n",
       "   290,\n",
       "   33,\n",
       "   150,\n",
       "   6721,\n",
       "   7,\n",
       "   6,\n",
       "   492,\n",
       "   34,\n",
       "   626,\n",
       "   21,\n",
       "   3,\n",
       "   9,\n",
       "   1975,\n",
       "   1814,\n",
       "   42,\n",
       "   128,\n",
       "   10191,\n",
       "   2458,\n",
       "   723,\n",
       "   5,\n",
       "   37,\n",
       "   843,\n",
       "   19,\n",
       "   16,\n",
       "   262,\n",
       "   779,\n",
       "   6,\n",
       "   28,\n",
       "   3,\n",
       "   9,\n",
       "   20513,\n",
       "   13324,\n",
       "   24,\n",
       "   6881,\n",
       "   300,\n",
       "   24,\n",
       "   843,\n",
       "   11,\n",
       "   3,\n",
       "   9,\n",
       "   11753,\n",
       "   314,\n",
       "   13572,\n",
       "   97,\n",
       "   5483,\n",
       "   5,\n",
       "   1]],\n",
       " 'attention_mask': [[1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1]],\n",
       " 'input_values': [[[-0.12020407617092133,\n",
       "    -0.1653224527835846,\n",
       "    -0.1735503077507019,\n",
       "    -0.17498230934143066,\n",
       "    -0.19953541457653046,\n",
       "    -0.23577621579170227,\n",
       "    -0.24683713912963867,\n",
       "    -0.2174825668334961,\n",
       "    -0.16787344217300415,\n",
       "    -0.12436828017234802,\n",
       "    -0.09646409749984741,\n",
       "    -0.0867970809340477,\n",
       "    -0.10407054424285889,\n",
       "    -0.14990076422691345,\n",
       "    -0.20137900114059448,\n",
       "    -0.22437000274658203,\n",
       "    -0.20633366703987122,\n",
       "    -0.16589826345443726,\n",
       "    -0.12814472615718842,\n",
       "    -0.09998133033514023,\n",
       "    -0.07396363466978073,\n",
       "    -0.047358810901641846,\n",
       "    -0.028253350406885147,\n",
       "    -0.02519729547202587,\n",
       "    -0.03813505545258522,\n",
       "    -0.06004884093999863,\n",
       "    -0.08240091800689697,\n",
       "    -0.0975915938615799,\n",
       "    -0.10037308186292648,\n",
       "    -0.09028348326683044,\n",
       "    -0.07186788320541382,\n",
       "    -0.050913747400045395,\n",
       "    -0.030881207436323166,\n",
       "    -0.013412216678261757,\n",
       "    -0.0006199721246957779,\n",
       "    0.005261551588773727,\n",
       "    0.004628034308552742,\n",
       "    0.001448052003979683,\n",
       "    0.0002724751830101013,\n",
       "    0.0020545832812786102,\n",
       "    0.0034048110246658325,\n",
       "    0.000942036509513855,\n",
       "    -0.0028722956776618958,\n",
       "    0.0012206044048070908,\n",
       "    0.022604765370488167,\n",
       "    0.061625681817531586,\n",
       "    0.10698467493057251,\n",
       "    0.14309127628803253,\n",
       "    0.16076503694057465,\n",
       "    0.16144591569900513,\n",
       "    0.1523571014404297,\n",
       "    0.13945254683494568,\n",
       "    0.12588971853256226,\n",
       "    0.11580602824687958,\n",
       "    0.11621987819671631,\n",
       "    0.13232719898223877,\n",
       "    0.1602543592453003,\n",
       "    0.18563959002494812,\n",
       "    0.1910196840763092,\n",
       "    0.1666920781135559,\n",
       "    0.1177995428442955,\n",
       "    0.06446965038776398,\n",
       "    0.034778617322444916,\n",
       "    0.051114246249198914,\n",
       "    0.11485672742128372,\n",
       "    0.20084086060523987,\n",
       "    0.2702696919441223,\n",
       "    0.29499223828315735,\n",
       "    0.2733737826347351,\n",
       "    0.2255636751651764,\n",
       "    0.17651522159576416,\n",
       "    0.14410188794136047,\n",
       "    0.13818146288394928,\n",
       "    0.1624041199684143,\n",
       "    0.21210172772407532,\n",
       "    0.2726902365684509,\n",
       "    0.32543110847473145,\n",
       "    0.35799700021743774,\n",
       "    0.37022221088409424,\n",
       "    0.37023356556892395,\n",
       "    0.36597785353660583,\n",
       "    0.36034464836120605,\n",
       "    0.3527178466320038,\n",
       "    0.34308692812919617,\n",
       "    0.3334016799926758,\n",
       "    0.32497358322143555,\n",
       "    0.31550082564353943,\n",
       "    0.2996405363082886,\n",
       "    0.27302348613739014,\n",
       "    0.23643861711025238,\n",
       "    0.19774752855300903,\n",
       "    0.17074733972549438,\n",
       "    0.1697082668542862,\n",
       "    0.19950315356254578,\n",
       "    0.24741166830062866,\n",
       "    0.28635263442993164,\n",
       "    0.29079145193099976,\n",
       "    0.25254330039024353,\n",
       "    0.18284529447555542,\n",
       "    0.1025969386100769,\n",
       "    0.03379593789577484,\n",
       "    -0.003205232322216034,\n",
       "    0.004932902753353119,\n",
       "    0.053037919104099274,\n",
       "    0.11255870759487152,\n",
       "    0.14580534398555756,\n",
       "    0.1301782876253128,\n",
       "    0.06969320774078369,\n",
       "    -0.013997266069054604,\n",
       "    -0.09587690234184265,\n",
       "    -0.15241648256778717,\n",
       "    -0.16239868104457855,\n",
       "    -0.11653287708759308,\n",
       "    -0.03177470713853836,\n",
       "    0.04896433651447296,\n",
       "    0.07989880442619324,\n",
       "    0.04121796786785126,\n",
       "    -0.05087191238999367,\n",
       "    -0.1586529016494751,\n",
       "    -0.2455986738204956,\n",
       "    -0.2893112897872925,\n",
       "    -0.2826400399208069,\n",
       "    -0.2326647788286209,\n",
       "    -0.16203905642032623,\n",
       "    -0.10528362542390823,\n",
       "    -0.09298984706401825,\n",
       "    -0.13223782181739807,\n",
       "    -0.20223471522331238,\n",
       "    -0.2723309397697449,\n",
       "    -0.3254571557044983,\n",
       "    -0.36341381072998047,\n",
       "    -0.39188238978385925,\n",
       "    -0.40663406252861023,\n",
       "    -0.39828720688819885,\n",
       "    -0.36765968799591064,\n",
       "    -0.3310704827308655,\n",
       "    -0.3093409240245819,\n",
       "    -0.3135175406932831,\n",
       "    -0.3401046395301819,\n",
       "    -0.374991238117218,\n",
       "    -0.39961040019989014,\n",
       "    -0.3980163633823395,\n",
       "    -0.36503830552101135,\n",
       "    -0.30997517704963684,\n",
       "    -0.25040972232818604,\n",
       "    -0.20107154548168182,\n",
       "    -0.1686878651380539,\n",
       "    -0.15510107576847076,\n",
       "    -0.15998698770999908,\n",
       "    -0.17788416147232056,\n",
       "    -0.19630511105060577,\n",
       "    -0.20275741815567017,\n",
       "    -0.19554126262664795,\n",
       "    -0.18515829741954803,\n",
       "    -0.1829674243927002,\n",
       "    -0.1891372948884964,\n",
       "    -0.19291839003562927,\n",
       "    -0.18398065865039825,\n",
       "    -0.16203080117702484,\n",
       "    -0.13578985631465912,\n",
       "    -0.11491695046424866,\n",
       "    -0.10442052036523819,\n",
       "    -0.10544980317354202,\n",
       "    -0.11790160834789276,\n",
       "    -0.13948485255241394,\n",
       "    -0.1625833511352539,\n",
       "    -0.17487621307373047,\n",
       "    -0.16577419638633728,\n",
       "    -0.13341276347637177,\n",
       "    -0.08596128225326538,\n",
       "    -0.03730221092700958,\n",
       "    -0.00175543874502182,\n",
       "    0.01001913845539093,\n",
       "    -0.00445178896188736,\n",
       "    -0.035287417471408844,\n",
       "    -0.06196965277194977,\n",
       "    -0.06401705741882324,\n",
       "    -0.03438049554824829,\n",
       "    0.015402927994728088,\n",
       "    0.06273547559976578,\n",
       "    0.08799022436141968,\n",
       "    0.0849330872297287,\n",
       "    0.06172946095466614,\n",
       "    0.033480577170848846,\n",
       "    0.01215307042002678,\n",
       "    0.0012165289372205734,\n",
       "    -0.0015322715044021606,\n",
       "    0.0027324147522449493,\n",
       "    0.01618000864982605,\n",
       "    0.039771419018507004,\n",
       "    0.0685071125626564,\n",
       "    0.09342025220394135,\n",
       "    0.108097143471241,\n",
       "    0.11177773773670197,\n",
       "    0.10653398931026459,\n",
       "    0.09403418004512787,\n",
       "    0.07647891342639923,\n",
       "    0.05904901772737503,\n",
       "    0.048918940126895905,\n",
       "    0.05099041759967804,\n",
       "    0.06466639041900635,\n",
       "    0.0842396467924118,\n",
       "    0.102082759141922,\n",
       "    0.11288808286190033,\n",
       "    0.11684942245483398,\n",
       "    0.1188151016831398,\n",
       "    0.12274503707885742,\n",
       "    0.12651684880256653,\n",
       "    0.1235920637845993,\n",
       "    0.11067038774490356,\n",
       "    0.09265612065792084,\n",
       "    0.07915351539850235,\n",
       "    0.07714328914880753,\n",
       "    0.08833093196153641,\n",
       "    0.11215750873088837,\n",
       "    0.14792796969413757,\n",
       "    0.19231630861759186,\n",
       "    0.23644718527793884,\n",
       "    0.26804119348526,\n",
       "    0.277679979801178,\n",
       "    0.2636975646018982,\n",
       "    0.2328656017780304,\n",
       "    0.19855159521102905,\n",
       "    0.17788009345531464,\n",
       "    0.18642845749855042,\n",
       "    0.2295527160167694,\n",
       "    0.2947717010974884,\n",
       "    0.35332658886909485,\n",
       "    0.3744494318962097,\n",
       "    0.3448132574558258,\n",
       "    0.2785339653491974,\n",
       "    0.20896640419960022,\n",
       "    0.16861101984977722,\n",
       "    0.17282631993293762,\n",
       "    0.21706876158714294,\n",
       "    0.28391557931900024,\n",
       "    0.35095638036727905,\n",
       "    0.39690902829170227,\n",
       "    0.40862470865249634,\n",
       "    0.3875100910663605,\n",
       "    0.34863972663879395,\n",
       "    0.31079912185668945,\n",
       "    0.28600257635116577,\n",
       "    0.2776695489883423,\n",
       "    0.2856842875480652,\n",
       "    0.30917051434516907,\n",
       "    0.3438618779182434,\n",
       "    0.38039684295654297,\n",
       "    0.40848857164382935,\n",
       "    0.42278847098350525,\n",
       "    0.4239083528518677,\n",
       "    0.41542211174964905,\n",
       "    0.40235528349876404,\n",
       "    0.3915788233280182,\n",
       "    0.38911813497543335,\n",
       "    0.39384180307388306,\n",
       "    0.3949698209762573,\n",
       "    0.37893128395080566,\n",
       "    0.3402601480484009,\n",
       "    0.28622445464134216,\n",
       "    0.2324015498161316,\n",
       "    0.1953161060810089,\n",
       "    0.1870330572128296,\n",
       "    0.21030622720718384,\n",
       "    0.2536395788192749,\n",
       "    0.2921661138534546,\n",
       "    0.2993707060813904,\n",
       "    0.2631714940071106,\n",
       "    0.19244906306266785,\n",
       "    0.10899827629327774,\n",
       "    0.03509160131216049,\n",
       "    -0.011631406843662262,\n",
       "    -0.017972871661186218,\n",
       "    0.01980067789554596,\n",
       "    0.08557109534740448,\n",
       "    0.14232556521892548,\n",
       "    0.1508162021636963,\n",
       "    0.09610775113105774,\n",
       "    -0.0020412206649780273,\n",
       "    -0.10381796956062317,\n",
       "    -0.173039972782135,\n",
       "    -0.1898217499256134,\n",
       "    -0.15099391341209412,\n",
       "    -0.0705677717924118,\n",
       "    0.01744730770587921,\n",
       "    0.06703571230173111,\n",
       "    0.045328956097364426,\n",
       "    -0.04289500415325165,\n",
       "    -0.15681123733520508,\n",
       "    -0.24845671653747559,\n",
       "    -0.29185691475868225,\n",
       "    -0.2881125211715698,\n",
       "    -0.25117409229278564,\n",
       "    -0.19633565843105316,\n",
       "    -0.1404569447040558,\n",
       "    -0.10298261046409607,\n",
       "    -0.09861874580383301,\n",
       "    -0.12918780744075775,\n",
       "    -0.18556031584739685,\n",
       "    -0.2557990849018097,\n",
       "    -0.3273797333240509,\n",
       "    -0.3833960294723511,\n",
       "    -0.40540796518325806,\n",
       "    -0.38683998584747314,\n",
       "    -0.34224238991737366,\n",
       "    -0.29854726791381836,\n",
       "    -0.27613532543182373,\n",
       "    -0.27961811423301697,\n",
       "    -0.30357640981674194,\n",
       "    -0.33933138847351074,\n",
       "    -0.3731207251548767,\n",
       "    -0.38501501083374023,\n",
       "    -0.3600025773048401,\n",
       "    -0.3029037117958069,\n",
       "    -0.23753222823143005,\n",
       "    -0.18750756978988647,\n",
       "    -0.15925654768943787,\n",
       "    -0.1446094661951065,\n",
       "    -0.13548317551612854,\n",
       "    -0.13082878291606903,\n",
       "    -0.13087327778339386,\n",
       "    -0.13178479671478271,\n",
       "    -0.12999212741851807,\n",
       "    -0.12841595709323883,\n",
       "    -0.13331246376037598,\n",
       "    -0.1445624828338623,\n",
       "    -0.15239450335502625,\n",
       "    -0.14550775289535522,\n",
       "    -0.12146908789873123,\n",
       "    -0.08861276507377625,\n",
       "    -0.05928797274827957,\n",
       "    -0.04245298355817795,\n",
       "    -0.0413883700966835,\n",
       "    -0.055423617362976074,\n",
       "    -0.08126314729452133,\n",
       "    -0.11160504072904587,\n",
       "    -0.13339629769325256,\n",
       "    -0.13089430332183838,\n",
       "    -0.09551724046468735,\n",
       "    -0.03602840006351471,\n",
       "    0.022062577307224274,\n",
       "    0.05137460678815842,\n",
       "    0.040955185890197754,\n",
       "    0.002448849380016327,\n",
       "    -0.03985561430454254,\n",
       "    -0.064466193318367,\n",
       "    -0.06149416044354439,\n",
       "    -0.032813165336847305,\n",
       "    0.011323902755975723,\n",
       "    0.05625917762517929,\n",
       "    0.08807119727134705,\n",
       "    0.09876794368028641,\n",
       "    0.08807671815156937,\n",
       "    0.06114121153950691,\n",
       "    0.025539882481098175,\n",
       "    -0.010002180933952332,\n",
       "    -0.03683110326528549,\n",
       "    -0.049135226756334305,\n",
       "    -0.04620737209916115,\n",
       "    -0.03156593441963196,\n",
       "    -0.01021961122751236,\n",
       "    0.01264292374253273,\n",
       "    0.03136833757162094,\n",
       "    0.04067153483629227,\n",
       "    0.03821166604757309,\n",
       "    0.02613573893904686,\n",
       "    0.00964009016752243,\n",
       "    -0.005943188443779945,\n",
       "    -0.017239201813936234,\n",
       "    -0.02373882755637169,\n",
       "    -0.027712903916835785,\n",
       "    -0.0322888158261776,\n",
       "    -0.03793061524629593,\n",
       "    -0.040551021695137024,\n",
       "    -0.03427361696958542,\n",
       "    -0.017042778432369232,\n",
       "    0.0063802748918533325,\n",
       "    0.02705681510269642,\n",
       "    0.03759582340717316,\n",
       "    0.03603816032409668,\n",
       "    0.025392279028892517,\n",
       "    0.01028168760240078,\n",
       "    -0.005586232990026474,\n",
       "    -0.018466297537088394,\n",
       "    -0.021727101877331734,\n",
       "    -0.0064650410786271095,\n",
       "    0.03158436715602875,\n",
       "    0.08433852344751358,\n",
       "    0.13244768977165222,\n",
       "    0.1569869965314865,\n",
       "    0.1518235206604004,\n",
       "    0.12595272064208984,\n",
       "    0.09634563326835632,\n",
       "    0.07983774691820145,\n",
       "    0.08810241520404816,\n",
       "    0.12290477752685547,\n",
       "    0.17187725007534027,\n",
       "    0.21178773045539856,\n",
       "    0.22204342484474182,\n",
       "    0.19841933250427246,\n",
       "    0.15417763590812683,\n",
       "    0.10901208221912384,\n",
       "    0.07836590707302094,\n",
       "    0.07095808535814285,\n",
       "    0.08972539007663727,\n",
       "    0.1298431009054184,\n",
       "    0.17711998522281647,\n",
       "    0.21361280977725983,\n",
       "    0.22815385460853577,\n",
       "    0.22162212431430817,\n",
       "    0.2024487853050232,\n",
       "    0.17904427647590637,\n",
       "    0.15729273855686188,\n",
       "    0.14271554350852966,\n",
       "    0.1412605196237564,\n",
       "    0.1562993824481964,\n",
       "    0.18530838191509247,\n",
       "    0.22006839513778687,\n",
       "    0.25036054849624634,\n",
       "    0.26851505041122437,\n",
       "    0.2724667191505432,\n",
       "    0.2663646340370178,\n",
       "    0.2588444948196411,\n",
       "    0.2593763768672943,\n",
       "    0.27307677268981934,\n",
       "    0.2956804633140564,\n",
       "    0.3130137026309967,\n",
       "    0.30866509675979614,\n",
       "    0.27612778544425964,\n",
       "    0.22437536716461182,\n",
       "    0.1704365760087967,\n",
       "    0.12702077627182007,\n",
       "    0.09900250285863876,\n",
       "    0.08953825384378433,\n",
       "    0.10201758146286011,\n",
       "    0.1307094246149063,\n",
       "    0.15344424545764923,\n",
       "    0.14288289844989777,\n",
       "    0.08981238305568695,\n",
       "    0.013139087706804276,\n",
       "    -0.055114880204200745,\n",
       "    -0.0924251526594162,\n",
       "    -0.09338255226612091,\n",
       "    -0.06318613141775131,\n",
       "    -0.01428452879190445,\n",
       "    0.02963823825120926,\n",
       "    0.037204399704933167,\n",
       "    -0.011498082429170609,\n",
       "    -0.1059616357088089,\n",
       "    -0.20778901875019073,\n",
       "    -0.27404212951660156,\n",
       "    -0.28071892261505127,\n",
       "    -0.230933278799057,\n",
       "    -0.149815171957016,\n",
       "    -0.07369217276573181,\n",
       "    -0.035613372921943665,\n",
       "    -0.04984390735626221,\n",
       "    -0.10525564849376678,\n",
       "    -0.17510047554969788,\n",
       "    -0.2353014349937439,\n",
       "    -0.2745462954044342,\n",
       "    -0.2903916537761688,\n",
       "    -0.28215491771698,\n",
       "    -0.25173699855804443,\n",
       "    -0.20917841792106628,\n",
       "    -0.17188668251037598,\n",
       "    -0.15523186326026917,\n",
       "    -0.16406303644180298,\n",
       "    -0.19340097904205322,\n",
       "    -0.23500987887382507,\n",
       "    -0.28072038292884827,\n",
       "    -0.3201494812965393,\n",
       "    -0.3398846983909607,\n",
       "    -0.3303661346435547,\n",
       "    -0.29604125022888184,\n",
       "    -0.25708019733428955,\n",
       "    -0.23734429478645325,\n",
       "    -0.24771654605865479,\n",
       "    -0.27989915013313293,\n",
       "    -0.3154042065143585,\n",
       "    -0.3392099142074585,\n",
       "    -0.3452131152153015,\n",
       "    -0.3327579200267792,\n",
       "    -0.3034045994281769,\n",
       "    -0.26248615980148315,\n",
       "    -0.2197115123271942,\n",
       "    -0.18352974951267242,\n",
       "    -0.15458327531814575,\n",
       "    -0.12756507098674774,\n",
       "    -0.10051131248474121,\n",
       "    -0.07989508658647537,\n",
       "    -0.07453564554452896,\n",
       "    -0.08575290441513062,\n",
       "    -0.1058882623910904,\n",
       "    -0.12619322538375854,\n",
       "    -0.14342373609542847,\n",
       "    -0.15740515291690826,\n",
       "    -0.16433724761009216,\n",
       "    -0.15598119795322418,\n",
       "    -0.12715496122837067,\n",
       "    -0.08379415422677994,\n",
       "    -0.04294774681329727,\n",
       "    -0.02381204068660736,\n",
       "    -0.03624887019395828,\n",
       "    -0.07445347309112549,\n",
       "    -0.11965154856443405,\n",
       "    -0.15027883648872375,\n",
       "    -0.153569757938385,\n",
       "    -0.13136714696884155,\n",
       "    -0.09691096842288971,\n",
       "    -0.06596013158559799,\n",
       "    -0.049066562205553055,\n",
       "    -0.049090757966041565,\n",
       "    -0.06269509345293045,\n",
       "    -0.0825013518333435,\n",
       "    -0.09893442690372467,\n",
       "    -0.10310646891593933,\n",
       "    -0.09090080857276917,\n",
       "    -0.06556423008441925,\n",
       "    -0.03595359995961189,\n",
       "    -0.011126546189188957,\n",
       "    0.004419606178998947,\n",
       "    0.010943721979856491,\n",
       "    0.009615883231163025,\n",
       "    -0.000629102811217308,\n",
       "    -0.02143857628107071,\n",
       "    -0.0499686598777771,\n",
       "    -0.0764923244714737,\n",
       "    -0.08891722559928894,\n",
       "    -0.08113520592451096,\n",
       "    -0.05744452029466629,\n",
       "    -0.028996296226978302,\n",
       "    -0.006124118342995644,\n",
       "    0.006624987348914146,\n",
       "    0.010366570204496384,\n",
       "    0.009265502914786339,\n",
       "    0.007882509380578995,\n",
       "    0.008534682914614677,\n",
       "    0.009391017258167267,\n",
       "    0.0059377700090408325,\n",
       "    -0.003989815711975098,\n",
       "    -0.016685940325260162,\n",
       "    -0.025428712368011475,\n",
       "    -0.02697063982486725,\n",
       "    -0.023643922060728073,\n",
       "    -0.018371062353253365,\n",
       "    -0.009467260912060738,\n",
       "    0.007151424884796143,\n",
       "    0.030402004718780518,\n",
       "    0.050562869757413864,\n",
       "    0.05504758656024933,\n",
       "    0.038409601897001266,\n",
       "    0.007665732875466347,\n",
       "    -0.02086465246975422,\n",
       "    -0.03021782822906971,\n",
       "    -0.011552760377526283,\n",
       "    0.031194068491458893,\n",
       "    0.08287163078784943,\n",
       "    0.12426291406154633,\n",
       "    0.14116233587265015,\n",
       "    0.13071100413799286,\n",
       "    0.10232528299093246,\n",
       "    0.07342153042554855,\n",
       "    0.061751026660203934,\n",
       "    0.07715156674385071,\n",
       "    0.11655103415250778,\n",
       "    0.16534176468849182,\n",
       "    0.2046239674091339,\n",
       "    0.2200639247894287,\n",
       "    0.20775625109672546,\n",
       "    0.17498689889907837,\n",
       "    0.1361534595489502,\n",
       "    0.10574333369731903,\n",
       "    0.09213430434465408,\n",
       "    0.09622297435998917,\n",
       "    0.11489838361740112,\n",
       "    0.14437660574913025,\n",
       "    0.17935149371623993,\n",
       "    0.2106965333223343,\n",
       "    0.22765076160430908,\n",
       "    0.22457461059093475,\n",
       "    0.2053723931312561,\n",
       "    0.18091368675231934,\n",
       "    0.16299185156822205,\n",
       "    0.16042441129684448,\n",
       "    0.1770181506872177,\n",
       "    0.20859529078006744,\n",
       "    0.2420310378074646,\n",
       "    0.26219844818115234,\n",
       "    0.2638947367668152,\n",
       "    0.2562656104564667,\n",
       "    0.25348448753356934,\n",
       "    0.26210522651672363,\n",
       "    0.27945762872695923,\n",
       "    0.3018297553062439,\n",
       "    0.32802197337150574,\n",
       "    0.3527107536792755,\n",
       "    0.3618685007095337,\n",
       "    0.3418389558792114,\n",
       "    0.2940729856491089,\n",
       "    0.23735402524471283,\n",
       "    0.1941106915473938,\n",
       "    0.17652525007724762,\n",
       "    0.18529266119003296,\n",
       "    0.21532079577445984,\n",
       "    0.2563266158103943,\n",
       "    0.2895919978618622,\n",
       "    0.2925061881542206,\n",
       "    0.25310277938842773,\n",
       "    0.18151304125785828,\n",
       "    0.10642379522323608,\n",
       "    0.05985177308320999,\n",
       "    0.0619426965713501,\n",
       "    0.11199454963207245,\n",
       "    0.18610289692878723,\n",
       "    0.24419733881950378,\n",
       "    0.24926216900348663,\n",
       "    0.190385103225708,\n",
       "    0.09137357026338577,\n",
       "    -0.00447947159409523,\n",
       "    -0.06119034066796303,\n",
       "    -0.06652697920799255,\n",
       "    -0.02947886660695076,\n",
       "    0.031163210049271584,\n",
       "    0.09436061978340149,\n",
       "    0.13941489160060883,\n",
       "    0.1500532031059265,\n",
       "    0.12138347327709198,\n",
       "    0.06332682073116302,\n",
       "    -0.004501957446336746,\n",
       "    -0.06296180188655853,\n",
       "    -0.10031741857528687,\n",
       "    -0.11205559968948364,\n",
       "    -0.09765619039535522,\n",
       "    -0.060674697160720825,\n",
       "    -0.012521792203187943,\n",
       "    0.02677014470100403,\n",
       "    0.03641354292631149,\n",
       "    0.007500700652599335,\n",
       "    -0.050461992621421814,\n",
       "    -0.11525824666023254,\n",
       "    -0.16455316543579102,\n",
       "    -0.18540090322494507,\n",
       "    -0.17699915170669556,\n",
       "    -0.14980454742908478,\n",
       "    -0.12254826724529266,\n",
       "    -0.11466033011674881,\n",
       "    -0.13513250648975372,\n",
       "    -0.17641712725162506,\n",
       "    -0.2205338031053543,\n",
       "    -0.25250670313835144,\n",
       "    -0.2682725787162781,\n",
       "    -0.2711150646209717,\n",
       "    -0.2636833190917969,\n",
       "    -0.2455771267414093,\n",
       "    -0.2174762785434723,\n",
       "    -0.1848134994506836,\n",
       "    -0.15588641166687012,\n",
       "    -0.13635247945785522,\n",
       "    -0.12547898292541504,\n",
       "    -0.11755498498678207,\n",
       "    -0.10776301473379135,\n",
       "    -0.09805075824260712,\n",
       "    -0.09718253463506699,\n",
       "    -0.1130402460694313,\n",
       "    -0.14304611086845398,\n",
       "    -0.17235934734344482,\n",
       "    -0.1831640899181366,\n",
       "    -0.16748502850532532,\n",
       "    -0.13259515166282654,\n",
       "    -0.09569813311100006,\n",
       "    -0.07384495437145233,\n",
       "    -0.07642128318548203,\n",
       "    -0.10253617912530899,\n",
       "    -0.14211514592170715,\n",
       "    -0.17995674908161163,\n",
       "    -0.20227554440498352,\n",
       "    -0.2030140608549118,\n",
       "    -0.1859390288591385,\n",
       "    -0.1613377183675766,\n",
       "    -0.1402931660413742,\n",
       "    -0.13029158115386963,\n",
       "    -0.13329778611660004,\n",
       "    -0.14559507369995117,\n",
       "    -0.15936467051506042,\n",
       "    -0.16636128723621368,\n",
       "    -0.16201715171337128,\n",
       "    -0.1466922163963318,\n",
       "    -0.12316816300153732,\n",
       "    -0.09381268918514252,\n",
       "    -0.06115942448377609,\n",
       "    -0.03076852113008499,\n",
       "    -0.011440273374319077,\n",
       "    -0.0106342863291502,\n",
       "    -0.02887505665421486,\n",
       "    -0.05834440886974335,\n",
       "    -0.08651022613048553,\n",
       "    -0.10174396634101868,\n",
       "    -0.09821414947509766,\n",
       "    -0.07864047586917877,\n",
       "    -0.0528767928481102,\n",
       "    -0.03128185123205185,\n",
       "    -0.017131928354501724,\n",
       "    -0.005780819803476334,\n",
       "    0.007703270763158798,\n",
       "    0.021037917584180832,\n",
       "    0.02671949565410614,\n",
       "    0.021117646247148514,\n",
       "    0.00901763141155243,\n",
       "    -0.0019555147737264633,\n",
       "    -0.009262433275580406,\n",
       "    -0.015591992065310478,\n",
       "    -0.022139588370919228,\n",
       "    -0.02446267381310463,\n",
       "    -0.01558036170899868,\n",
       "    0.00838065892457962,\n",
       "    0.04557931423187256,\n",
       "    0.08855937421321869,\n",
       "    0.12492259591817856,\n",
       "    0.1402437388896942,\n",
       "    0.1253211945295334,\n",
       "    0.08389444649219513,\n",
       "    0.03346235677599907,\n",
       "    -0.0027567297220230103,\n",
       "    -0.0068516805768013,\n",
       "    0.026420127600431442,\n",
       "    0.0877242386341095,\n",
       "    0.15605181455612183,\n",
       "    0.20683035254478455,\n",
       "    0.22385261952877045,\n",
       "    0.20830151438713074,\n",
       "    0.17738783359527588,\n",
       "    0.15311695635318756,\n",
       "    0.1502503603696823,\n",
       "    0.17153045535087585,\n",
       "    0.20986752212047577,\n",
       "    0.2524488866329193,\n",
       "    0.28474536538124084,\n",
       "    0.2958314120769501,\n",
       "    0.28396594524383545,\n",
       "    0.2574814260005951,\n",
       "    0.2286837100982666,\n",
       "    0.20605158805847168,\n",
       "    0.19238023459911346,\n",
       "    0.18924136459827423,\n",
       "    0.19995808601379395,\n",
       "    0.22534134984016418,\n",
       "    0.25699159502983093,\n",
       "    0.2784111499786377,\n",
       "    0.27618706226348877,\n",
       "    0.25094789266586304,\n",
       "    0.21660463511943817,\n",
       "    0.18902301788330078,\n",
       "    0.17644424736499786,\n",
       "    0.17987437546253204,\n",
       "    0.19831541180610657,\n",
       "    0.22915196418762207,\n",
       "    0.2637442648410797,\n",
       "    0.2876637876033783,\n",
       "    0.28992316126823425,\n",
       "    0.27266886830329895,\n",
       "    0.25031429529190063,\n",
       "    0.23883658647537231,\n",
       "    0.24622023105621338,\n",
       "    0.2711118757724762,\n",
       "    0.30614012479782104,\n",
       "    0.34006381034851074,\n",
       "    0.3594523072242737,\n",
       "    0.3535092771053314,\n",
       "    0.32023146748542786,\n",
       "    0.2680726945400238,\n",
       "    0.2119341343641281,\n",
       "    0.1682678908109665,\n",
       "    0.15168452262878418,\n",
       "    0.1694698929786682,\n",
       "    0.21297687292099,\n",
       "    0.2546333074569702,\n",
       "    0.2604365944862366,\n",
       "    0.21329231560230255,\n",
       "    0.1278558075428009,\n",
       "    0.04220139980316162,\n",
       "    -0.00723111629486084,\n",
       "    -0.006496340036392212,\n",
       "    0.03308384120464325,\n",
       "    0.08611731231212616,\n",
       "    0.1257314831018448,\n",
       "    0.13138088583946228,\n",
       "    0.09415185451507568,\n",
       "    0.021085500717163086,\n",
       "    -0.06566563248634338,\n",
       "    -0.13842619955539703,\n",
       "    -0.17767927050590515,\n",
       "    -0.17987160384655,\n",
       "    -0.1546732485294342,\n",
       "    -0.11700396239757538,\n",
       "    -0.08187578618526459,\n",
       "    -0.06332392245531082,\n",
       "    -0.07242780923843384,\n",
       "    -0.11209160089492798,\n",
       "    -0.17330922186374664,\n",
       "    -0.23837187886238098,\n",
       "    -0.28932076692581177,\n",
       "    -0.31466802954673767,\n",
       "    -0.31099480390548706,\n",
       "    -0.28271323442459106,\n",
       "    -0.24308669567108154,\n",
       "    -0.21322819590568542,\n",
       "    -0.21387970447540283,\n",
       "    -0.2524089217185974,\n",
       "    -0.31582945585250854,\n",
       "    -0.3780539035797119,\n",
       "    -0.41698601841926575,\n",
       "    -0.4277016222476959,\n",
       "    -0.42178744077682495,\n",
       "    -0.4156211018562317,\n",
       "    -0.4190322756767273,\n",
       "    -0.4329201579093933,\n",
       "    -0.45451509952545166,\n",
       "    -0.4824850261211395,\n",
       "    -0.5164911150932312,\n",
       "    -0.5531595349311829,\n",
       "    -0.5844502449035645,\n",
       "    -0.6013813018798828,\n",
       "    -0.6000804901123047,\n",
       "    -0.584714949131012,\n",
       "    -0.564723014831543,\n",
       "    -0.5483414530754089,\n",
       "    -0.5369052886962891,\n",
       "    -0.5240768194198608,\n",
       "    -0.5014706254005432,\n",
       "    -0.4675001800060272,\n",
       "    -0.4322664737701416,\n",
       "    -0.4128100275993347,\n",
       "    -0.4210817217826843,\n",
       "    -0.45443838834762573,\n",
       "    -0.4966883659362793,\n",
       "    -0.5279530882835388,\n",
       "    -0.5346752405166626,\n",
       "    -0.5139169692993164,\n",
       "    -0.4729764461517334,\n",
       "    -0.4269399642944336,\n",
       "    -0.39345601201057434,\n",
       "    -0.38409513235092163,\n",
       "    -0.3971552550792694,\n",
       "    -0.41906648874282837,\n",
       "    -0.4345247149467468,\n",
       "    -0.43640226125717163,\n",
       "    -0.4270833730697632,\n",
       "    -0.41268813610076904,\n",
       "    -0.3981110155582428,\n",
       "    -0.3866282105445862,\n",
       "    -0.3805915117263794,\n",
       "    -0.3799426853656769,\n",
       "    -0.3811115026473999,\n",
       "    -0.3798229694366455,\n",
       "    -0.3751584589481354,\n",
       "    -0.36874252557754517,\n",
       "    -0.359066903591156,\n",
       "    -0.3389601707458496,\n",
       "    -0.30184298753738403,\n",
       "    -0.2510971426963806,\n",
       "    -0.2013067752122879,\n",
       "    -0.16855016350746155,\n",
       "    -0.15935808420181274,\n",
       "    -0.16897422075271606,\n",
       "    -0.18846842646598816,\n",
       "    -0.21136631071567535,\n",
       "    -0.23383429646492004,\n",
       "    -0.25170740485191345,\n",
       "    -0.2602539658546448,\n",
       "    -0.2568679451942444,\n",
       "    -0.2424210160970688,\n",
       "    -0.21972519159317017,\n",
       "    -0.1920541226863861,\n",
       "    -0.16363643109798431,\n",
       "    -0.13962343335151672,\n",
       "    -0.12310688197612762,\n",
       "    -0.1121029406785965,\n",
       "    -0.10168531537055969,\n",
       "    -0.09060666710138321,\n",
       "    -0.0847468227148056,\n",
       "    -0.0918445810675621,\n",
       "    -0.11203013360500336,\n",
       "    -0.13434824347496033,\n",
       "    -0.14328020811080933,\n",
       "    -0.12880322337150574,\n",
       "    -0.09136894345283508,\n",
       "    -0.04045319929718971,\n",
       "    0.008879558183252811,\n",
       "    0.03954089432954788,\n",
       "    0.03875886648893356,\n",
       "    0.0069556706584990025,\n",
       "    -0.038362499326467514,\n",
       "    -0.07084006071090698,\n",
       "    -0.07159186899662018,\n",
       "    -0.0402214452624321,\n",
       "    0.008053887635469437,\n",
       "    0.05406623333692551,\n",
       "    0.08392654359340668,\n",
       "    0.09167727082967758,\n",
       "    0.07958637177944183,\n",
       "    0.05853082239627838,\n",
       "    0.04455956816673279,\n",
       "    0.04958486557006836,\n",
       "    0.07336010038852692,\n",
       "    0.10583033412694931,\n",
       "    0.13773024082183838,\n",
       "    0.16698536276817322,\n",
       "    0.19408729672431946,\n",
       "    0.21453478932380676,\n",
       "    0.22021950781345367,\n",
       "    0.20885327458381653,\n",
       "    0.18899060785770416,\n",
       "    0.17385141551494598,\n",
       "    0.17163558304309845,\n",
       "    0.1831928938627243,\n",
       "    0.2066604197025299,\n",
       "    0.2401072084903717,\n",
       "    0.27881306409835815,\n",
       "    0.3135800063610077,\n",
       "    0.33538389205932617,\n",
       "    0.3420472741127014,\n",
       "    0.3392375111579895,\n",
       "    0.3354172110557556,\n",
       "    0.3370017409324646,\n",
       "    0.3471311330795288,\n",
       "    0.36551254987716675,\n",
       "    0.3874831795692444,\n",
       "    0.4051787257194519,\n",
       "    0.4128713607788086,\n",
       "    0.41217324137687683,\n",
       "    0.4111390709877014,\n",
       "    0.4182409644126892,\n",
       "    0.4381471276283264,\n",
       "    0.47238367795944214,\n",
       "    0.5200753211975098,\n",
       "    0.5743085741996765,\n",
       "    0.6185504794120789,\n",
       "    0.6318982839584351,\n",
       "    0.6035411357879639,\n",
       "    0.544615626335144,\n",
       "    0.4849197268486023,\n",
       "    0.45498722791671753,\n",
       "    0.46721920371055603,\n",
       "    0.5097957253456116,\n",
       "    0.5554700493812561,\n",
       "    0.5767822861671448,\n",
       "    0.5583953857421875,\n",
       "    0.5028076171875,\n",
       "    0.4294193983078003,\n",
       "    0.3669125437736511,\n",
       "    0.34012916684150696,\n",
       "    0.35733070969581604,\n",
       "    0.4062562584877014,\n",
       "    0.46197447180747986,\n",
       "    0.5000836253166199,\n",
       "    0.5057075023651123,\n",
       "    0.47515565156936646,\n",
       "    0.41436687111854553,\n",
       "    0.33761656284332275,\n",
       "    0.26458823680877686,\n",
       "    0.21341189742088318,\n",
       "    0.1929921805858612,\n",
       "    0.2008993923664093,\n",
       "    0.2277841866016388,\n",
       "    0.2624560594558716,\n",
       "    0.2928149998188019,\n",
       "    0.30515211820602417,\n",
       "    0.2875683307647705,\n",
       "    0.23780786991119385,\n",
       "    0.16866923868656158,\n",
       "    0.10425440967082977,\n",
       "    0.06768950074911118,\n",
       "    0.0681740790605545,\n",
       "    0.09612864255905151,\n",
       "    0.1296297013759613,\n",
       "    0.1474933922290802,\n",
       "    0.13989019393920898,\n",
       "    0.10989153385162354,\n",
       "    0.06709298491477966,\n",
       "    0.02044929936528206,\n",
       "    -0.02389439381659031,\n",
       "    -0.0605497881770134,\n",
       "    -0.08368515223264694,\n",
       "    -0.08971840143203735,\n",
       "    -0.08172298967838287,\n",
       "    -0.07062137126922607,\n",
       "    -0.0702815055847168,\n",
       "    -0.0887104719877243,\n",
       "    -0.12188883125782013,\n",
       "    -0.1562851071357727,\n",
       "    -0.17934423685073853,\n",
       "    -0.1892649531364441,\n",
       "    -0.19489099085330963,\n",
       "    -0.2058160901069641,\n",
       "    -0.222568541765213,\n",
       "    -0.23595592379570007,\n",
       "    -0.23457077145576477,\n",
       "    -0.2123173177242279,\n",
       "    -0.17086714506149292,\n",
       "    ...]]],\n",
       " 'padding_mask': [[1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   ...]]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "expected sequence of length 88 at dim 2 (got 153)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m trainer.train()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda\\envs\\NLP2\\Lib\\site-packages\\transformers\\trainer.py:2240\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2238\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2239\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2240\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m inner_training_loop(\n\u001b[32m   2241\u001b[39m         args=args,\n\u001b[32m   2242\u001b[39m         resume_from_checkpoint=resume_from_checkpoint,\n\u001b[32m   2243\u001b[39m         trial=trial,\n\u001b[32m   2244\u001b[39m         ignore_keys_for_eval=ignore_keys_for_eval,\n\u001b[32m   2245\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda\\envs\\NLP2\\Lib\\site-packages\\transformers\\trainer.py:2509\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2507\u001b[39m update_step += \u001b[32m1\u001b[39m\n\u001b[32m   2508\u001b[39m num_batches = args.gradient_accumulation_steps \u001b[38;5;28;01mif\u001b[39;00m update_step != (total_updates - \u001b[32m1\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m remainder\n\u001b[32m-> \u001b[39m\u001b[32m2509\u001b[39m batch_samples, num_items_in_batch = \u001b[38;5;28mself\u001b[39m.get_batch_samples(epoch_iterator, num_batches, args.device)\n\u001b[32m   2510\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, inputs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(batch_samples):\n\u001b[32m   2511\u001b[39m     step += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda\\envs\\NLP2\\Lib\\site-packages\\transformers\\trainer.py:5263\u001b[39m, in \u001b[36mTrainer.get_batch_samples\u001b[39m\u001b[34m(self, epoch_iterator, num_batches, device)\u001b[39m\n\u001b[32m   5261\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_batches):\n\u001b[32m   5262\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m5263\u001b[39m         batch_samples.append(\u001b[38;5;28mnext\u001b[39m(epoch_iterator))\n\u001b[32m   5264\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m   5265\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda\\envs\\NLP2\\Lib\\site-packages\\accelerate\\data_loader.py:566\u001b[39m, in \u001b[36mDataLoaderShard.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    564\u001b[39m \u001b[38;5;66;03m# We iterate one batch ahead to check when we are at the end\u001b[39;00m\n\u001b[32m    565\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m566\u001b[39m     current_batch = \u001b[38;5;28mnext\u001b[39m(dataloader_iter)\n\u001b[32m    567\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m    568\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda\\envs\\NLP2\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:733\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    731\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    732\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m data = \u001b[38;5;28mself\u001b[39m._next_data()\n\u001b[32m    734\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    735\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    736\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    739\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda\\envs\\NLP2\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:789\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    787\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    788\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m789\u001b[39m     data = \u001b[38;5;28mself\u001b[39m._dataset_fetcher.fetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    790\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    791\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda\\envs\\NLP2\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:55\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.collate_fn(data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda\\envs\\NLP2\\Lib\\site-packages\\transformers\\data\\data_collator.py:93\u001b[39m, in \u001b[36mdefault_data_collator\u001b[39m\u001b[34m(features, return_tensors)\u001b[39m\n\u001b[32m     87\u001b[39m \u001b[38;5;66;03m# In this function we'll make the assumption that all `features` in the batch\u001b[39;00m\n\u001b[32m     88\u001b[39m \u001b[38;5;66;03m# have the same attributes.\u001b[39;00m\n\u001b[32m     89\u001b[39m \u001b[38;5;66;03m# So we will look at the first element as a proxy for what attributes exist\u001b[39;00m\n\u001b[32m     90\u001b[39m \u001b[38;5;66;03m# on the whole batch.\u001b[39;00m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m return_tensors == \u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch_default_data_collator(features)\n\u001b[32m     94\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m return_tensors == \u001b[33m\"\u001b[39m\u001b[33mtf\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m tf_default_data_collator(features)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda\\envs\\NLP2\\Lib\\site-packages\\transformers\\data\\data_collator.py:159\u001b[39m, in \u001b[36mtorch_default_data_collator\u001b[39m\u001b[34m(features)\u001b[39m\n\u001b[32m    157\u001b[39m             batch[k] = torch.from_numpy(np.stack([f[k] \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m features]))\n\u001b[32m    158\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m159\u001b[39m             batch[k] = torch.tensor([f[k] \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m features])\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m batch\n",
      "\u001b[31mValueError\u001b[39m: expected sequence of length 88 at dim 2 (got 153)"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.9 ('NLP2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "11c7becfb3ab913813bd9aa8c016a376309325bf0d122f29c83fa200e32f21b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
